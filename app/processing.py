# app/processing.py
import logging
import os
import aiofiles
from pypdf import PdfReader

# "Import" ‡∏ï‡∏±‡∏ß "‡∏´‡∏±‡πà‡∏ô" (Chunking) ‡πÅ‡∏•‡∏∞ "‡πÅ‡∏õ‡∏•‡∏á" (Embedding)
from sentence_transformers import SentenceTransformer
from langchain_text_splitters import RecursiveCharacterTextSplitter

from app import models, crud
from app.database import SessionLocal # <-- "Import" Session

UPLOAD_DIRECTORY = "/app/uploads"
log = logging.getLogger("uvicorn.error")

# --- "‡πÇ‡∏´‡∏•‡∏î" AI (‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß) ---
# (‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠ Model ‡∏ó‡∏µ‡πà "‡πÄ‡∏•‡πá‡∏Å" ‡πÅ‡∏•‡∏∞ "‡πÄ‡∏£‡πá‡∏ß" ... 384 ‡∏°‡∏¥‡∏ï‡∏¥)
log.info("Loading SentenceTransformer model...")
EMBEDDING_MODEL = SentenceTransformer("all-MiniLM-L6-v2")
log.info("Model loaded.")
# ---------------------------------


# "‡∏™‡∏£‡πâ‡∏≤‡∏á" ‡∏ï‡∏±‡∏ß "‡∏´‡∏±‡πà‡∏ô" (‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏´‡∏±‡πà‡∏ô‡∏ó‡∏µ‡∏•‡∏∞ 1000 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200, # (‡πÉ‡∏´‡πâ‡∏°‡∏±‡∏ô "‡πÄ‡∏´‡∏•‡∏∑‡πà‡∏≠‡∏°" ‡∏Å‡∏±‡∏ô 200)
    length_function=len,
)


async def save_extract_chunk_and_embed(
    document_id: int,
    filename: str,
    content_type: str,
    content: bytes
):
    """
    "‡∏£‡∏∑‡πâ‡∏≠" ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡∏°‡πà‡∏´‡∏°‡∏î:
    1. "‡πÄ‡∏ã‡∏ü" ‡πÑ‡∏ü‡∏•‡πå (‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß)
    2. "‡∏™‡∏Å‡∏±‡∏î" Text
    3. "‡∏´‡∏±‡πà‡∏ô" (Chunk) Text
    4. "‡πÅ‡∏õ‡∏•‡∏á" (Embed) Text
    5. "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å" Chunks + Vectors ‡∏•‡∏á DB
    """

    os.makedirs(UPLOAD_DIRECTORY, exist_ok=True)
    file_path = os.path.join(UPLOAD_DIRECTORY, f"doc_{document_id}_{filename}")

    log.info(f"--- ü§ñ TASK START (Doc ID: {document_id}) ---")

    try:
        # 1. "‡πÄ‡∏ã‡∏ü" ‡πÑ‡∏ü‡∏•‡πå (‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß)
        async with aiofiles.open(file_path, "wb") as out_file:
            await out_file.write(content)

        log.info(f"File saved. Extracting text...")

        # 2. "‡∏™‡∏Å‡∏±‡∏î" Text
        extracted_text = ""
        if content_type == "application/pdf":
            reader = PdfReader(file_path)
            for page in reader.pages:
                extracted_text += page.extract_text() + "\n"
        else:
            extracted_text = content.decode("utf-8")

        log.info(f"Text extracted. (Length: {len(extracted_text)})")

        # 3. "‡∏´‡∏±‡πà‡∏ô" (Chunk) Text
        log.info(f"Chunking text...")
        chunks = text_splitter.split_text(extracted_text)
        log.info(f"Text chunked into {len(chunks)} pieces.")

        # 4. "‡πÅ‡∏õ‡∏•‡∏á" (Embed) Text (‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà "‡∏´‡∏ô‡∏±‡∏Å" ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
        log.info(f"Embedding chunks...")
        # (‡πÄ‡∏£‡∏≤ "‡πÅ‡∏õ‡∏•‡∏á" ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î... ‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
        embeddings = EMBEDDING_MODEL.encode(chunks)
        log.info(f"Embeddings created.")

        # 5. "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å" Chunks + Vectors ‡∏•‡∏á DB
        # (‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á "‡∏™‡∏£‡πâ‡∏≤‡∏á" DB Session "‡πÉ‡∏´‡∏°‡πà" ...
        #  ...‡πÄ‡∏û‡∏£‡∏≤‡∏∞ Task ‡∏ô‡∏µ‡πâ "‡∏≠‡∏¥‡∏™‡∏£‡∏∞" ‡∏à‡∏≤‡∏Å API)

        # (‡πÄ‡∏£‡∏≤‡∏à‡∏∞ "‡∏™‡∏£‡πâ‡∏≤‡∏á" List ‡∏Ç‡∏≠‡∏á "‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏î‡∏¥‡∏ö" (Objects)
        db_chunks = []
        for i in range(len(chunks)):
            db_chunks.append(
                models.Chunk(
                    text=chunks[i],
                    embedding=embeddings[i], # <-- "Vector"
                    document_id=document_id
                )
            )

        # "‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠" DB (‡πÅ‡∏ö‡∏ö "‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß")
        async with SessionLocal() as db:
            log.info(f"Saving {len(db_chunks)} chunks to DB...")
            # "‡∏¢‡∏±‡∏î" (Bulk Save) ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
            db.add_all(db_chunks)
            await db.commit() # <-- "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å"

        log.info(f"--- ü§ñ TASK DONE (Doc ID: {document_id}) ---")

    except Exception as e:
        log.error(f"Error processing file {file_path}: {e}", exc_info=True)
        log.error(f"--- ü§ñ TASK FAILED (Doc ID: {document_id}) ---")

    finally:
        # "‡∏•‡∏ö" ‡πÑ‡∏ü‡∏•‡πå PDF/TXT ‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß (‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏ã‡∏ü‡πÑ‡∏ß‡πâ) ‡∏ó‡∏¥‡πâ‡∏á
        if os.path.exists(file_path):
            os.remove(file_path)
        log.info(f"Cleaned up {file_path}")